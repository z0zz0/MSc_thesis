{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from deep_ILM_GN import ConvNet\n",
    "from datasetADNI import AdniImagesDataset\n",
    "from dataloaderADNI import get_kfCV_loaders, split_train_test\n",
    "from hooks import get_all_layers, visualization\n",
    "from stats import calc_intresting_statistics\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy import stats, ndimage\n",
    "\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from itertools import cycle\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# device config\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which model we running here\n",
    "NAME = \"deep_ILM_GN\"\n",
    "# cv parameter\n",
    "k_cv = 5\n",
    "# params for dataset and loader\n",
    "num_workers = 16\n",
    "n_classes = 3\n",
    "# hyper params.\n",
    "n_epochs = 100\n",
    "batch_size = 4\n",
    "lr = 0.0001\n",
    "\n",
    "# Reduced data set (1 scan per subject) set this parameter to True. If full dataset is wished to be used set this to False \n",
    "unique_subjects=True\n",
    "if unique_subjects:\n",
    "    PATH_TO_FIGS = \"figs_reduced_data\"\n",
    "    PATH_TO_MODELS = \"models_reduced_data\"\n",
    "    PATH_TO_LOGS = \"logs_reduced\"\n",
    "else:\n",
    "    PATH_TO_FIGS = \"figs\"\n",
    "    PATH_TO_MODELS = \"models\"\n",
    "    PATH_TO_LOGS = \"logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes = {'AD': 0, 'MCI': 1, 'CN': 2}\n",
      "Counts = {'AD': 112, 'MCI': 112, 'CN': 112}\n",
      "train_dataset = 270, test_dataset = 66\n"
     ]
    }
   ],
   "source": [
    "#transform = transforms.Compose([transforms.ToTensor()])\n",
    "dataset = AdniImagesDataset(\"../data_balanced\", unique_subjects=unique_subjects)\n",
    "train_dataset, test_dataset = split_train_test(dataset, n_classes=n_classes, test_ratio=0.2)\n",
    "print(f\"train_dataset = {len(train_dataset)}, test_dataset = {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (pool_stride_2): MaxPool3d(kernel_size=(2, 2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (pool_stride_1): MaxPool3d(kernel_size=(2, 2, 2), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  (droput_3d_05): Dropout3d(p=0.5, inplace=False)\n",
      "  (droput_1d_02): Dropout(p=0.25, inplace=False)\n",
      "  (conv1): Conv3d(1, 5, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
      "  (relu1): ReLU()\n",
      "  (ilm_gn1): ilm_GN(\n",
      "    (fc_embed): Sequential(\n",
      "      (0): Linear(in_features=1, out_features=2, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "    (fc_weight): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=1, out_features=2, bias=False)\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Linear(in_features=2, out_features=1, bias=False)\n",
      "      (2): Sigmoid()\n",
      "    )\n",
      "    (fc_bias): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=1, out_features=2, bias=False)\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Linear(in_features=2, out_features=1, bias=False)\n",
      "      (2): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (conv2): Conv3d(5, 5, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
      "  (relu2): ReLU()\n",
      "  (ilm_gn2): ilm_GN(\n",
      "    (fc_embed): Sequential(\n",
      "      (0): Linear(in_features=1, out_features=2, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "    (fc_weight): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=1, out_features=2, bias=False)\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Linear(in_features=2, out_features=1, bias=False)\n",
      "      (2): Sigmoid()\n",
      "    )\n",
      "    (fc_bias): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=1, out_features=2, bias=False)\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Linear(in_features=2, out_features=1, bias=False)\n",
      "      (2): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (conv3): Conv3d(5, 5, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (relu3): ReLU()\n",
      "  (ilm_gn3): ilm_GN(\n",
      "    (fc_embed): Sequential(\n",
      "      (0): Linear(in_features=1, out_features=2, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "    (fc_weight): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=1, out_features=2, bias=False)\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Linear(in_features=2, out_features=1, bias=False)\n",
      "      (2): Sigmoid()\n",
      "    )\n",
      "    (fc_bias): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=1, out_features=2, bias=False)\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Linear(in_features=2, out_features=1, bias=False)\n",
      "      (2): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (conv4): Conv3d(5, 5, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (relu4): ReLU()\n",
      "  (ilm_gn4): ilm_GN(\n",
      "    (fc_embed): Sequential(\n",
      "      (0): Linear(in_features=1, out_features=2, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "    (fc_weight): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=1, out_features=2, bias=False)\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Linear(in_features=2, out_features=1, bias=False)\n",
      "      (2): Sigmoid()\n",
      "    )\n",
      "    (fc_bias): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=1, out_features=2, bias=False)\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Linear(in_features=2, out_features=1, bias=False)\n",
      "      (2): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (conv5): Conv3d(5, 5, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (relu5): ReLU()\n",
      "  (ilm_gn5): ilm_GN(\n",
      "    (fc_embed): Sequential(\n",
      "      (0): Linear(in_features=1, out_features=2, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "    (fc_weight): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=1, out_features=2, bias=False)\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Linear(in_features=2, out_features=1, bias=False)\n",
      "      (2): Sigmoid()\n",
      "    )\n",
      "    (fc_bias): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=1, out_features=2, bias=False)\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Linear(in_features=2, out_features=1, bias=False)\n",
      "      (2): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (conv6): Conv3d(5, 10, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (relu6): ReLU()\n",
      "  (ilm_gn6): ilm_GN(\n",
      "    (fc_embed): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=2, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "    (fc_weight): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=2, out_features=2, bias=False)\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Linear(in_features=2, out_features=2, bias=False)\n",
      "      (2): Sigmoid()\n",
      "    )\n",
      "    (fc_bias): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=2, out_features=2, bias=False)\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Linear(in_features=2, out_features=2, bias=False)\n",
      "      (2): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (conv7): Conv3d(10, 10, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (relu7): ReLU()\n",
      "  (ilm_gn7): ilm_GN(\n",
      "    (fc_embed): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=2, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "    (fc_weight): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=2, out_features=2, bias=False)\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Linear(in_features=2, out_features=2, bias=False)\n",
      "      (2): Sigmoid()\n",
      "    )\n",
      "    (fc_bias): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=2, out_features=2, bias=False)\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Linear(in_features=2, out_features=2, bias=False)\n",
      "      (2): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (conv8): Conv3d(10, 10, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (relu8): ReLU()\n",
      "  (ilm_gn8): ilm_GN(\n",
      "    (fc_embed): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=2, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "    (fc_weight): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=2, out_features=2, bias=False)\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Linear(in_features=2, out_features=2, bias=False)\n",
      "      (2): Sigmoid()\n",
      "    )\n",
      "    (fc_bias): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=2, out_features=2, bias=False)\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Linear(in_features=2, out_features=2, bias=False)\n",
      "      (2): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (conv9): Conv3d(10, 10, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (relu9): ReLU()\n",
      "  (ilm_gn9): ilm_GN(\n",
      "    (fc_embed): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=2, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "    (fc_weight): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=2, out_features=2, bias=False)\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Linear(in_features=2, out_features=2, bias=False)\n",
      "      (2): Sigmoid()\n",
      "    )\n",
      "    (fc_bias): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=2, out_features=2, bias=False)\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Linear(in_features=2, out_features=2, bias=False)\n",
      "      (2): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (conv10): Conv3d(10, 10, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (relu10): ReLU()\n",
      "  (ilm_gn10): ilm_GN(\n",
      "    (fc_embed): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=2, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "    (fc_weight): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=2, out_features=2, bias=False)\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Linear(in_features=2, out_features=2, bias=False)\n",
      "      (2): Sigmoid()\n",
      "    )\n",
      "    (fc_bias): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=2, out_features=2, bias=False)\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Linear(in_features=2, out_features=2, bias=False)\n",
      "      (2): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (conv11): Conv3d(10, 10, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (relu11): ReLU()\n",
      "  (ilm_gn11): ilm_GN(\n",
      "    (fc_embed): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=2, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "    (fc_weight): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=2, out_features=2, bias=False)\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Linear(in_features=2, out_features=2, bias=False)\n",
      "      (2): Sigmoid()\n",
      "    )\n",
      "    (fc_bias): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=2, out_features=2, bias=False)\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Linear(in_features=2, out_features=2, bias=False)\n",
      "      (2): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (conv12): Conv3d(10, 20, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (relu12): ReLU()\n",
      "  (ilm_gn12): ilm_GN(\n",
      "    (fc_embed): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=2, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "    (fc_weight): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=4, out_features=2, bias=False)\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Linear(in_features=2, out_features=4, bias=False)\n",
      "      (2): Sigmoid()\n",
      "    )\n",
      "    (fc_bias): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=4, out_features=2, bias=False)\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Linear(in_features=2, out_features=4, bias=False)\n",
      "      (2): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (conv13): Conv3d(20, 20, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (relu13): ReLU()\n",
      "  (ilm_gn13): ilm_GN(\n",
      "    (fc_embed): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=2, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "    (fc_weight): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=4, out_features=2, bias=False)\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Linear(in_features=2, out_features=4, bias=False)\n",
      "      (2): Sigmoid()\n",
      "    )\n",
      "    (fc_bias): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=4, out_features=2, bias=False)\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Linear(in_features=2, out_features=4, bias=False)\n",
      "      (2): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (conv14): Conv3d(20, 20, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (relu14): ReLU()\n",
      "  (ilm_gn14): ilm_GN(\n",
      "    (fc_embed): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=2, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "    (fc_weight): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=4, out_features=2, bias=False)\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Linear(in_features=2, out_features=4, bias=False)\n",
      "      (2): Sigmoid()\n",
      "    )\n",
      "    (fc_bias): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=4, out_features=2, bias=False)\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Linear(in_features=2, out_features=4, bias=False)\n",
      "      (2): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (conv15): Conv3d(20, 20, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (relu15): ReLU()\n",
      "  (ilm_gn15): ilm_GN(\n",
      "    (fc_embed): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=2, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "    (fc_weight): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=4, out_features=2, bias=False)\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Linear(in_features=2, out_features=4, bias=False)\n",
      "      (2): Sigmoid()\n",
      "    )\n",
      "    (fc_bias): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=4, out_features=2, bias=False)\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Linear(in_features=2, out_features=4, bias=False)\n",
      "      (2): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (conv16): Conv3d(20, 20, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (relu16): ReLU()\n",
      "  (ilm_gn16): ilm_GN(\n",
      "    (fc_embed): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=2, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "    (fc_weight): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=4, out_features=2, bias=False)\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Linear(in_features=2, out_features=4, bias=False)\n",
      "      (2): Sigmoid()\n",
      "    )\n",
      "    (fc_bias): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=4, out_features=2, bias=False)\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Linear(in_features=2, out_features=4, bias=False)\n",
      "      (2): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (conv17): Conv3d(20, 20, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (relu17): ReLU()\n",
      "  (ilm_gn17): ilm_GN(\n",
      "    (fc_embed): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=2, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "    (fc_weight): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=4, out_features=2, bias=False)\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Linear(in_features=2, out_features=4, bias=False)\n",
      "      (2): Sigmoid()\n",
      "    )\n",
      "    (fc_bias): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=4, out_features=2, bias=False)\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Linear(in_features=2, out_features=4, bias=False)\n",
      "      (2): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (conv18): Conv3d(20, 40, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (relu18): ReLU()\n",
      "  (ilm_gn18): ilm_GN(\n",
      "    (fc_embed): Sequential(\n",
      "      (0): Linear(in_features=8, out_features=1, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "    (fc_weight): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=8, out_features=1, bias=False)\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Linear(in_features=1, out_features=8, bias=False)\n",
      "      (2): Sigmoid()\n",
      "    )\n",
      "    (fc_bias): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=8, out_features=1, bias=False)\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Linear(in_features=1, out_features=8, bias=False)\n",
      "      (2): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (conv19): Conv3d(40, 80, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (relu19): ReLU()\n",
      "  (ilm_gn19): ilm_GN(\n",
      "    (fc_embed): Sequential(\n",
      "      (0): Linear(in_features=16, out_features=3, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "    (fc_weight): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=16, out_features=3, bias=False)\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Linear(in_features=3, out_features=16, bias=False)\n",
      "      (2): Sigmoid()\n",
      "    )\n",
      "    (fc_bias): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=16, out_features=3, bias=False)\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Linear(in_features=3, out_features=16, bias=False)\n",
      "      (2): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (fc1): Linear(in_features=11760, out_features=65, bias=True)\n",
      "  (relu20): ReLU()\n",
      "  (ln20): LayerNorm((65,), eps=1e-05, elementwise_affine=True)\n",
      "  (fc2): Linear(in_features=65, out_features=40, bias=True)\n",
      "  (relu21): ReLU()\n",
      "  (ln21): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
      "  (fc3): Linear(in_features=40, out_features=20, bias=True)\n",
      "  (relu22): ReLU()\n",
      "  (ln22): LayerNorm((20,), eps=1e-05, elementwise_affine=True)\n",
      "  (fc4): Linear(in_features=20, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = ConvNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV: [1]/[5], Epoch: [1/100]\r"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 1; 10.76 GiB total capacity; 9.59 GiB already allocated; 7.44 MiB free; 9.66 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-428a49b99f5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;31m# forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/stud1/e/edlpll15/thesis/very_deep_models/deep_ILM_GN.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool_stride_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0milm_gn16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool_stride_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu17\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv17\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/stud1/e/edlpll15/thesis/very_deep_models/ilm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 1; 10.76 GiB total capacity; 9.59 GiB already allocated; 7.44 MiB free; 9.66 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "######\n",
    "## Run this cell for k-fold CV\n",
    "######\n",
    "writer_path = f\"./{PATH_TO_LOGS}/{datetime.now().strftime('%Y%m%d-%H%M%S')}/\"\n",
    "writer_train_path = writer_path + f\"{NAME}_train_batchSize_{batch_size}/\"\n",
    "writer_val_path = writer_path + f\"{NAME}_validation_batchSize_{batch_size}/\"\n",
    "\n",
    "l1 = {0:[], 49:[], 99:[]}\n",
    "l10 = {0:[], 49:[], 99:[]}\n",
    "l19 = {0:[], 49:[], 99:[]}\n",
    "\n",
    "feat_map1 = {0:None, 49:None, 99:None}\n",
    "feat_map12 = {0:None, 49:None, 99:None}\n",
    "\n",
    "all_predicted = []\n",
    "all_true = []\n",
    "aggregate_stats = []\n",
    "best_val_acc = 0.0\n",
    "\n",
    "# Lists holds aggregated info for each cv\n",
    "train_acc = [np.zeros(k_cv) for i in range(n_epochs)]\n",
    "train_loss = [np.zeros(k_cv) for i in range(n_epochs)]\n",
    "val_acc = [np.zeros(k_cv) for i in range(n_epochs)]\n",
    "val_loss = [np.zeros(k_cv) for i in range(n_epochs)]\n",
    "\n",
    "## Go through all cv-partitions\n",
    "for n_cv in range(k_cv):\n",
    "    model = ConvNet().to(device)\n",
    "    if n_cv == k_cv-1:\n",
    "        get_all_layers(model) ## adding hooks to all layers. But only for one of the models, due to hardware performance.\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    train_loader, val_loader = get_kfCV_loaders(train_dataset, n_classes=n_classes, k=0.245, batch_size=batch_size, num_workers=num_workers)\n",
    "    \n",
    "    \n",
    "    n_train_samples = len(train_loader.dataset)\n",
    "    n_val_samples = len(val_loader.dataset)\n",
    "    \n",
    "    ## go through n epochs per k-fold cv\n",
    "    for epoch in range(n_epochs):\n",
    "        print(f'CV: [{n_cv+1}]/[{k_cv}], Epoch: [{epoch+1}/{n_epochs}]', end='\\r')\n",
    "        tmp_train_loss = 0\n",
    "        tmp_train_corr = 0\n",
    "        tmp_val_loss = 0\n",
    "        tmp_val_corr = 0\n",
    "        \n",
    "        ### Training\n",
    "        model.train()\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # forward\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)            \n",
    "\n",
    "            # backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            tmp_train_loss +=  loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            tmp_train_corr += (predicted==labels).sum().item()\n",
    "            \n",
    "        train_acc[epoch][n_cv] = 100 * tmp_train_corr/n_train_samples\n",
    "        train_loss[epoch][n_cv] = tmp_train_loss/n_train_samples\n",
    "        \n",
    "        if epoch in [0, 49, 99]:\n",
    "            l1[epoch].extend( model.conv1.weight.grad.flatten().cpu().detach().tolist() )\n",
    "            l10[epoch].extend( model.conv10.weight.grad.flatten().cpu().detach().tolist() )\n",
    "            l19[epoch].extend( model.fc3.weight.grad.flatten().cpu().detach().tolist() )\n",
    "            if n_cv == k_cv-1: \n",
    "                feat_map1[epoch] = visualization[\"conv1\"][0]\n",
    "                feat_map12[epoch] = visualization[\"conv12\"][0]\n",
    "        #writer_train.add_scalar('loss', train_running_loss / n_train_samples, epoch)\n",
    "        #writer_train.add_scalar('accuracy', 100 * train_running_acc / n_train_samples, epoch)\n",
    "        \n",
    "        \n",
    "        ### Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in val_loader:\n",
    "                imgs = imgs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # forward\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                tmp_val_loss +=  loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                tmp_val_corr += (predicted==labels).sum().item()\n",
    "                \n",
    "                if epoch == (n_epochs-1): ## last epoch, acquire stats\n",
    "                    all_true.extend(labels)\n",
    "                    all_predicted.extend(predicted)\n",
    "                \n",
    "            val_acc[epoch][n_cv] = 100 * tmp_val_corr/n_val_samples\n",
    "            val_loss[epoch][n_cv] = tmp_val_loss/n_val_samples\n",
    "            \n",
    "            if epoch == (n_epochs-1): ## last epoch, acquire stats\n",
    "                aggregate_stats.append(calc_intresting_statistics(all_true, all_predicted, [0,1,2]))\n",
    "                if val_acc[epoch][n_cv] > best_val_acc:\n",
    "                    best_val_acc = val_acc[epoch][n_cv]\n",
    "                    torch.save(model.state_dict(), f\"{PATH_TO_MODELS}/{NAME}/eval_grads_CNN_batchSize_{batch_size}\")\n",
    "                \n",
    "            #writer_val.add_scalar('loss', val_running_loss / n_val_samples, epoch)\n",
    "            #writer_val.add_scalar('accuracy', 100 * val_running_acc / n_val_samples, epoch)\n",
    "        \n",
    "## Val acc of best model\n",
    "print(f\"Best model val acc: {best_val_acc}\")\n",
    "\n",
    "## Statistics\n",
    "t = 2.776  # 95% confidence interval, t-value. d.f. = n-1 = 5-1 = 4 \n",
    "train_interval_acc = []\n",
    "val_interval_acc = []\n",
    "\n",
    "train_interval_loss = []\n",
    "val_interval_loss = []\n",
    "\n",
    "train_mean_acc = []\n",
    "val_mean_acc = []\n",
    "\n",
    "train_mean_loss = []\n",
    "val_mean_loss = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_interval_acc.append( t * np.std(train_acc[epoch], ddof=1) / (len(train_acc[epoch])**0.5) )\n",
    "    val_interval_acc.append( t * np.std(val_acc[epoch], ddof=1) / (len(val_acc[epoch])**0.5) )\n",
    "    \n",
    "    train_interval_loss.append( t * np.std(train_loss[epoch], ddof=1) / (len(train_loss[epoch]))**0.5 )\n",
    "    val_interval_loss.append( t * np.std(val_loss[epoch], ddof=1) / (len(val_loss[epoch]))**0.5 )\n",
    "    \n",
    "    train_mean_acc.append( np.mean(train_acc[epoch]) )\n",
    "    val_mean_acc.append( np.mean(val_acc[epoch]) )\n",
    "    \n",
    "    train_mean_loss.append( np.mean(train_loss[epoch]) )\n",
    "    val_mean_loss.append( np.mean(val_loss[epoch]) )\n",
    "\n",
    "## Write to tensorboard logs\n",
    "writer_train = SummaryWriter(writer_train_path)\n",
    "writer_val = SummaryWriter(writer_val_path)\n",
    "\n",
    "for epoch, (ta, tl, va, vl) in enumerate(zip(train_mean_acc, train_mean_loss, val_mean_acc, val_mean_loss)):\n",
    "    writer_train.add_scalar('accuracy', ta, epoch)\n",
    "    writer_train.add_scalar('loss', tl, epoch)\n",
    "    writer_val.add_scalar('accuracy', va, epoch)\n",
    "    writer_val.add_scalar('loss', vl, epoch)\n",
    "\n",
    "writer_train.close()\n",
    "writer_val.close()\n",
    "\n",
    "train_interval_acc = np.array(train_interval_acc)\n",
    "val_interval_acc = np.array(val_interval_acc)\n",
    "train_interval_loss = np.array(train_interval_loss)\n",
    "val_interval_loss = np.array(val_interval_loss)\n",
    "\n",
    "train_mean_acc = np.array(train_mean_acc)\n",
    "val_mean_acc = np.array(val_mean_acc)\n",
    "train_mean_loss = np.array(train_mean_loss)\n",
    "val_mean_loss = np.array(val_mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "stats_CI = {}\n",
    "for c_name in [\"AD\", \"MCI\", \"CN\"]:\n",
    "    stats_CI[c_name] = {}\n",
    "    for s in ['Precision', 'Sensitivity', 'Specificity', 'FPR', 'FNR']:\n",
    "        stats_CI[c_name][s] = []\n",
    "\n",
    "for (c_name, c) in zip([\"AD\", \"MCI\", \"CN\"], [0,1,2]):\n",
    "    for dicts in aggregate_stats:\n",
    "        for s in ['Precision', 'Sensitivity', 'Specificity', 'FPR', 'FNR']:\n",
    "            stats_CI[c_name][s].append(dicts[c][s])\n",
    "\n",
    "## Statistics\n",
    "stats_CI_95 = {}\n",
    "t = 2.776  # 95% confidence interval, t-value. d.f. = n-1 = 5-1 = 4 \n",
    "for c_name in [\"AD\", \"MCI\", \"CN\"]:\n",
    "    stats_CI_95[c_name] = {}\n",
    "    for s in ['Precision', 'Sensitivity', 'Specificity', 'FPR', 'FNR']: \n",
    "        stats_CI_95[c_name][s] = {\"mean\":np.mean(stats_CI[c_name][s]), \"CI\": t * np.std(stats_CI[c_name][s], ddof=1) / (len(stats_CI[c_name][s])**0.5)}\n",
    "\n",
    "dict_file = open(f\"{PATH_TO_FIGS}/{NAME}/{batch_size}/{NAME}_{batch_size}_stats_CI_95.json\", \"w\")\n",
    "json.dump(stats_CI_95, dict_file)\n",
    "dict_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to test the model\n",
    "test_loader =  torch.utils.data.DataLoader(test_dataset, batch_size = batch_size, shuffle = False, num_workers = num_workers)\n",
    "\n",
    "model = ConvNet().to(device)\n",
    "model.load_state_dict(torch.load(f\"{PATH_TO_MODELS}/{NAME}/eval_grads_CNN_batchSize_{batch_size}\"))\n",
    "get_all_layers(model)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    n_samples = 0\n",
    "    running_loss=0.0\n",
    "    n_class_corr = [0 for i in range(3)]\n",
    "    n_class_samples = [0 for i in range(3)]\n",
    "    total_pred = []\n",
    "    total_labels = []\n",
    "    total_pred_score = []\n",
    "    for imgs, labels in test_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(imgs)\n",
    "        # max returns (value, index)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        running_loss += criterion(outputs, labels)\n",
    "        total_pred.extend(predicted.cpu().detach().tolist())\n",
    "        total_labels.extend(labels.cpu().detach().tolist())\n",
    "        total_pred_score.extend(outputs.cpu().detach().numpy())\n",
    "        \n",
    "    for pred, label  in zip(total_pred, total_labels):\n",
    "        if (label == pred):\n",
    "            n_class_corr[label] += 1\n",
    "        n_class_samples[label] += 1\n",
    "        \n",
    "    acc = 100 * np.sum(np.array(total_pred) == np.array(total_labels)) / n_samples\n",
    "    print(f\"Avarage test loss: {running_loss/n_samples}\")\n",
    "    print(f'Test Accuracy of the network: {acc}%')\n",
    "\n",
    "    for i in range(3):\n",
    "        acc = 100 * n_class_corr[i] / n_class_samples[i]\n",
    "        print(f'Accuracy of {i}: {acc} %')\n",
    "        \n",
    "test_feat_map1 = visualization[\"conv1\"][0]\n",
    "test_feat_map12 = visualization[\"conv12\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(total_labels, total_pred)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(cf_matrix, annot=True, cbar=False, ax=ax)\n",
    "\n",
    "ax.set_title(f'Confusion matrix of {NAME} model')\n",
    "ax.set_ylabel(\"True\")\n",
    "ax.set_xlabel(\"Predicted\")\n",
    "plt.show()\n",
    "fig.savefig(f\"{PATH_TO_FIGS}/{NAME}/{batch_size}/cf_matrix_batchSize_{batch_size}.png\", dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ROC PLOT\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(3):\n",
    "    fpr[i], tpr[i], _ = roc_curve(nn.functional.one_hot(torch.as_tensor(total_labels))[:, i], np.array(total_pred_score)[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "fig = plt.figure()\n",
    "colors = cycle(['green', 'blue', 'red'])\n",
    "for i, color in zip(range(3), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2, label='ROC curve of class {0} (area = {1:0.4f})'''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title(f'ROC Curves, {NAME} model')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "fig.savefig(f\"{PATH_TO_FIGS}/{NAME}/{batch_size}/ROCAUC_plot_batchSize_{batch_size}.png\", dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Acc plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(list(range(n_epochs)), train_mean_acc, color='b', label=\"Training\")\n",
    "ax.fill_between(list(range(n_epochs)), np.clip((train_mean_acc-train_interval_acc) , a_min=0, a_max=100), np.clip((train_mean_acc+train_interval_acc) , a_min=0, a_max=100), color='b', alpha=.1)\n",
    "ax.plot(list(range(n_epochs)), val_mean_acc, color='g', label=\"Validation\")\n",
    "ax.fill_between(list(range(n_epochs)), np.clip((val_mean_acc-val_interval_acc), a_min=0, a_max=100), np.clip((val_mean_acc+val_interval_acc), a_min=0, a_max=100), color='g', alpha=.1)\n",
    "ax.set_ylabel(\"Accuracy, %\")\n",
    "ax.set_xlabel(\"Epochs\")\n",
    "ax.set_title(f\"Accuracy of {NAME} model\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig.savefig(f\"{PATH_TO_FIGS}/{NAME}/{batch_size}/accuracy_plot_batchSize_{batch_size}.png\", dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loss plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(list(range(n_epochs)), train_mean_loss, color='b', label=\"Training\")\n",
    "ax.fill_between(list(range(n_epochs)), np.clip((train_mean_loss-train_interval_loss), a_min=0, a_max=None), np.clip((train_mean_loss+train_interval_loss), a_min=0, a_max=None), color='b', alpha=.1)\n",
    "ax.plot(list(range(n_epochs)), val_mean_loss, color='g', label=\"Validation\")\n",
    "ax.fill_between(list(range(n_epochs)), np.clip((val_mean_loss-val_interval_loss), a_min=0, a_max=None), np.clip((val_mean_loss+val_interval_loss), a_min=0, a_max=None), color='g', alpha=.1)\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_xlabel(\"Epochs\")\n",
    "ax.set_title(f\"Loss of {NAME} model\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig.savefig(f\"{PATH_TO_FIGS}/{NAME}/{batch_size}/loss_plot_batchSize_{batch_size}.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, big_axes = plt.subplots( figsize=(16, 10) , nrows=3, ncols=1, sharey=True) \n",
    "n_epoch = [\"1\",\"50\",\"100\"]\n",
    "for row, big_ax in enumerate(big_axes, start=1):\n",
    "    big_ax.set_title(\"Epoch: %s \\n\" % n_epoch[row-1], fontsize=14)\n",
    "\n",
    "    # Turn off axis lines and ticks of the big subplot \n",
    "    # obs alpha is 0 in RGBA string!\n",
    "    big_ax.tick_params(labelcolor=(1.,1.,1., 0.0), top='off', bottom='off', left='off', right='off')\n",
    "    # removes the white frame\n",
    "    big_ax._frameon = False\n",
    "\n",
    "l_name = [\"conv1\",\"conv10\",\"fc3\"]\n",
    "for i, epoch in enumerate([0, 49, 99]):\n",
    "    for j, layer  in enumerate([l1,l10,l19]):\n",
    "        n_ax = i*3+j+1\n",
    "        ax = fig.add_subplot(3,3,n_ax)\n",
    "        ax.set_title(\"Layer: \"+l_name[j], fontsize=12)\n",
    "        sns.kdeplot(layer[epoch], ax=ax)\n",
    "\n",
    "fig.set_facecolor('w')\n",
    "fig.suptitle(\"Density plot of gradients\", fontsize=16, x=0.5175)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(f\"{PATH_TO_FIGS}/{NAME}/{batch_size}/gradients_density_plot_batchSize_{batch_size}.png\", dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, big_axes = plt.subplots( figsize=(16, 10) , nrows=3, ncols=1, sharey=True) \n",
    "n_epoch = [\"1\", \"50\", \"100\"]\n",
    "for row, big_ax in enumerate(big_axes, start=1):\n",
    "    big_ax.set_title(\"Epoch: %s \\n\" % n_epoch[row-1], fontsize=14)\n",
    "\n",
    "    # Turn off axis lines and ticks of the big subplot \n",
    "    # obs alpha is 0 in RGBA string!\n",
    "    big_ax.tick_params(labelcolor=(1.,1.,1., 0.0), top='off', bottom='off', left='off', right='off')\n",
    "    # removes the white frame\n",
    "    big_ax._frameon = False\n",
    "\n",
    "l_name = [\"conv1\",\"conv10\",\"fc3\"]\n",
    "for i, epoch in enumerate([0, 49, 99]):\n",
    "    for j, layer  in enumerate([l1,l10,l19]):\n",
    "        n_ax = i*3+j+1\n",
    "        ax = fig.add_subplot(3,3,n_ax)\n",
    "        ax.set_title(\"Layer: \"+l_name[j], fontsize=12)\n",
    "        sns.kdeplot(np.abs(layer[epoch]), ax=ax)\n",
    "\n",
    "fig.set_facecolor('w')\n",
    "fig.suptitle(\"Density plot of gradients' absolute values\", fontsize=16, x=0.5175)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(f\"{PATH_TO_FIGS}/{NAME}/{batch_size}/absolute_gradients_density_plot_batchSize_{batch_size}.png\", dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_name = [\"conv1\",\"conv10\",\"fc3\"]\n",
    "tmp_stat_str = \"\"\n",
    "for epoch in [0, 49, 99]:\n",
    "    tmp_stat_str += f\"Epoch: {epoch+1}\\n\"\n",
    "    for j, layer  in enumerate([l1,l10,l19]):\n",
    "        tmp_stat_str += f\"Layer:{l_name[j]}\\n\"\n",
    "        tmp_stat_str += str(stats.describe(np.abs(layer[epoch])))+\"\\n\\n\"\n",
    "    tmp_stat_str += \"\\n\"\n",
    "\n",
    "print(tmp_stat_str)\n",
    "file = open(f\"{PATH_TO_FIGS}/{NAME}/{batch_size}/stats_summary_batchSize_{batch_size}.txt\", \"w\") \n",
    "file.write(tmp_stat_str) \n",
    "file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 2.75))\n",
    "for i, epoch in enumerate([0, 49, 99]):\n",
    "    for j, f in enumerate(feat_map1[epoch]):\n",
    "        n_ax = i*5+j+1\n",
    "        ax = fig.add_subplot(3, 5, n_ax)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.imshow(ndimage.rotate(f[48], 90), cmap='gray') ## rotating to make it look neat in our LaTeX template\n",
    "\n",
    "\n",
    "#fig.set_facecolor('w')\n",
    "fig.suptitle(\"Feature maps of layer conv1 on training data\", fontsize=16)\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(wspace=0, hspace=0)\n",
    "fig.show()\n",
    "\n",
    "fig.savefig(f\"{PATH_TO_FIGS}/{NAME}/{batch_size}/featureMaps_conv1_trainData_batchSize_{batch_size}.png\", dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 4.5))\n",
    "for i, epoch in enumerate([0, 49, 99]):\n",
    "    for j, f in enumerate(feat_map12[epoch]):\n",
    "        n_ax = i*20+j+1\n",
    "        ax = fig.add_subplot(6, 10, n_ax)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.imshow(ndimage.rotate(f[14], 90), cmap='gray') ## rotating to make it look neat in our LaTeX template\n",
    "        #ax.invert_yaxis()\n",
    "\n",
    "\n",
    "#fig.set_facecolor('w')\n",
    "fig.suptitle(\"Feature maps of layer conv12 on training data\", fontsize=16)\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(f\"{PATH_TO_FIGS}/{NAME}/{batch_size}/featureMaps_conv12_trainData_batchSize_{batch_size}.png\", dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 1.45))\n",
    "for j, f in enumerate(test_feat_map1):\n",
    "    ax = fig.add_subplot(1, 5, j+1)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.imshow(ndimage.rotate(f[48], 90), cmap='gray') ## rotating to make it look neat in our LaTeX template\n",
    "\n",
    "\n",
    "#fig.set_facecolor('w')\n",
    "fig.suptitle(\"Feature maps of layer conv1 on test data\", fontsize=16)\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(wspace=0, hspace=0)\n",
    "fig.show()\n",
    "\n",
    "fig.savefig(f\"{PATH_TO_FIGS}/{NAME}/{batch_size}/featureMaps_conv1_testData_batchSize_{batch_size}.png\", dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 3.2))\n",
    "for j, f in enumerate(test_feat_map12):\n",
    "    ax = fig.add_subplot(4, 5, j+1)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.imshow(ndimage.rotate(f[14], 90), cmap='gray') ## rotating to make it look neat in our LaTeX template\n",
    "    #ax.invert_yaxis()\n",
    "\n",
    "\n",
    "#fig.set_facecolor('w')\n",
    "fig.suptitle(\"Feature maps of layer conv12 on test data\", fontsize=16)\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(f\"{PATH_TO_FIGS}/{NAME}/{batch_size}/featureMaps_conv12_testData_batchSize_{batch_size}.png\", dpi=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import LayerGradCam, LayerAttribution, visualization, GuidedGradCam\n",
    "from matplotlib import cm\n",
    "import cv2\n",
    "\n",
    "def predict_label(scan, model=model):\n",
    "    # Convert to a batch of 1\n",
    "    xb = scan.unsqueeze(0)\n",
    "    # Get predictions from model\n",
    "    yb = model(xb)\n",
    "    # Pick index with highest probability\n",
    "    output = F.softmax(yb, dim=1)\n",
    "    prediction_score, pred = torch.topk(output, 1)\n",
    "\n",
    "    return pred.squeeze()\n",
    "\n",
    "def min_max_norm(x): \n",
    "    max_val = np.max(x)\n",
    "    min_val = np.min(x)\n",
    "    y = (x-min_val) / (max_val-min_val)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 0   1       2\n",
    "width, height, depth = 160, 160, 96\n",
    "\n",
    "# for plotting\n",
    "grad_constraint = 0\n",
    "alpha_plt_value = 0.4\n",
    "\n",
    "## cases 14, 143 and 202\n",
    "for test_scan_number in [0, 23, 44]:\n",
    "    \n",
    "    classes = {0:\"AD\", 1:\"MCI\", 2:\"CN\"} #sets all the classes\n",
    "\n",
    "    scans, labels = test_dataset[test_scan_number] \n",
    "    case = classes[labels.item()]\n",
    "\n",
    "    print(f\"Scan is of class: {case}\")\n",
    "\n",
    "    layer_gc = LayerGradCam(model, model.conv19)\n",
    "    input = scans.unsqueeze(0).clone().detach().cuda().requires_grad_(True)\n",
    "\n",
    "    #Detta måste upsamplas! (GRADCAM)\n",
    "    #attr är downsamplad från (1,1,160,160,96) --> (1,1,5,5,3)\n",
    "    attr = layer_gc.attribute(input, target=labels.item())\n",
    "    attr_cpy = attr.cpu().detach().numpy().squeeze(0)\n",
    "\n",
    "    img = attr_cpy[0, :, :]\n",
    "    #print(\"attr_cpy[0, :, :].transpose(2,1,0)->\",attr_cpy[0, :, :].transpose(2,1,0).shape)\n",
    "\n",
    "    scan_resized = cv2.resize(img, (height, width), interpolation = cv2.INTER_CUBIC)\n",
    "    #print(\"scan_resized.shape:\", scan_resized.shape)\n",
    "\n",
    "    scan_tmp = np.expand_dims(scan_resized.transpose(2,1,0), 0)\n",
    "    #print(\"scan_tmp.shape:\",scan_tmp.shape)\n",
    "\n",
    "    img = scan_tmp[0, :, :]\n",
    "    #print(\"scan_tmp[0, :, :]->:\",scan_tmp[0, :, :].shape)\n",
    "\n",
    "    scan_resized_tmp = cv2.resize(img, (height, depth), interpolation=cv2.INTER_CUBIC)\n",
    "    #print(\"scan_resized_tmp.shape:\",scan_resized_tmp.shape)\n",
    "\n",
    "    ## depth width height -> width heigth depth\n",
    "    gradcam_final_upsampled = scan_resized_tmp.transpose(2,1,0)\n",
    "    print(\"gradcam_final_upsampled.shape:\", gradcam_final_upsampled.shape)\n",
    "\n",
    "\n",
    "  \n",
    "    #Nuvarande upsampling\n",
    "    #attribution = LayerAttribution.interpolate(attr, (160, 160, 96))[0][0]\n",
    "    \n",
    "    #Allt inom 0 - 1 (GRADCAM scan) \n",
    "    #selected_scan_grad = np.abs(attribution.cpu().detach().numpy())\n",
    "    selected_scan_grad = np.abs(gradcam_final_upsampled)\n",
    "    selected_scan_grad = min_max_norm(selected_scan_grad)\n",
    "    #nifti image\n",
    "    scans = scans[0].numpy()\n",
    "\n",
    "\n",
    "    ### SAGITTAL\n",
    "    ### SHOWING EVERY SECOND SLICE, FROM 40 TO 120 ###\n",
    "    fig = plt.figure(figsize=(12, 14))\n",
    "    cb_ax = fig.add_axes([.91,.124,.04,.754])\n",
    "    for i, slice_x in enumerate(range(40, 120, 2)):\n",
    "        #Activation values = (selected_slice_grad_x>grad_constraint)\n",
    "        selected_slice_grad_x = np.rot90(selected_scan_grad[slice_x, :, :])\n",
    "        selected_scan_x = np.rot90(scans[slice_x, :, :])\n",
    "        \n",
    "        alpha_x = np.zeros(selected_slice_grad_x.shape)\n",
    "        alpha_x[selected_slice_grad_x>grad_constraint]=alpha_plt_value\n",
    "\n",
    "        ax = fig.add_subplot(8,5,i+1)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.imshow(selected_scan_x, cmap=\"gray\")\n",
    "        ax.imshow(selected_slice_grad_x, cmap=\"jet\", alpha = alpha_x)\n",
    "        ax.annotate(f\"slice {slice_x}\", (0,0), xytext=(50.0,-3.0), xycoords='data', fontsize=\"large\")\n",
    "\n",
    "    #fig.tight_layout()\n",
    "    fig.subplots_adjust(wspace=0, hspace=0)\n",
    "    fig.colorbar(cm.ScalarMappable(cmap=\"jet\"), cax=cb_ax)\n",
    "    fig.savefig(f\"{PATH_TO_FIGS}/{NAME}/{batch_size}/maps/GradCam_{case}_case_sagittal_batchSize_{batch_size}.png\", dpi=100)\n",
    "\n",
    "    ### CORONAL\n",
    "    ### SHOWING EVERY SECOND SLICE, FROM 23 TO 140 ###\n",
    "    fig = plt.figure(figsize=(12, 14))\n",
    "    cb_ax = fig.add_axes([.91,.124,.04,.754])\n",
    "    for i, slice_y in enumerate(range(23, 141, 3)):\n",
    "        selected_slice_grad_y = np.rot90(selected_scan_grad[:, slice_y, :])\n",
    "        selected_scan_y = np.rot90(scans[:, slice_y, :])\n",
    "        alpha_y = np.zeros(selected_slice_grad_y.shape)\n",
    "        alpha_y[selected_slice_grad_y>grad_constraint]=alpha_plt_value\n",
    "\n",
    "\n",
    "        ax = fig.add_subplot(8,5,i+1)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.imshow(selected_scan_y, cmap=\"gray\")\n",
    "        ax.imshow(selected_slice_grad_y, cmap=\"jet\", alpha = alpha_y)\n",
    "        ax.annotate(f\"slice {slice_y}\", (0,0), xytext=(50.0,-3.0), xycoords='data', fontsize=\"large\")\n",
    "\n",
    "    #fig.tight_layout()\n",
    "    fig.subplots_adjust(wspace=0, hspace=0)\n",
    "    fig.colorbar(cm.ScalarMappable(cmap=\"jet\"), cax=cb_ax)\n",
    "    fig.savefig(f\"{PATH_TO_FIGS}/{NAME}/{batch_size}/maps/GradCam_{case}_case_coronal_batchSize_{batch_size}.png\", dpi=100)\n",
    "\n",
    "    ### AXIAL\n",
    "    ### SHOWING EVERY SECOND SLICE ###\n",
    "    fig = plt.figure(figsize=(12,18.5))\n",
    "    cb_ax = fig.add_axes([.91,.124,.04,.754])\n",
    "\n",
    "    for i, slice_z in enumerate(range(0, 96, 2)):\n",
    "        selected_slice_grad_z = selected_scan_grad[:, :, slice_z]\n",
    "        selected_scan_z = scans[:, :, slice_z]\n",
    "\n",
    "        alpha_z = np.zeros(selected_slice_grad_z.shape)\n",
    "        alpha_z[selected_slice_grad_z>grad_constraint]=alpha_plt_value\n",
    "\n",
    "        ax = fig.add_subplot(8,6,i+1)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.imshow(selected_scan_z, cmap=\"gray\")\n",
    "        ax.imshow(selected_slice_grad_z, cmap=\"jet\", alpha = alpha_z)\n",
    "        ax.annotate(f\"slice {slice_z}\", (0,0), xytext=(50.0,-3.0), xycoords='data', fontsize=\"large\")\n",
    "\n",
    "    #fig.tight_layout()\n",
    "    fig.subplots_adjust(wspace=0, hspace=0)\n",
    "    fig.colorbar(cm.ScalarMappable(cmap=\"jet\"), cax=cb_ax)\n",
    "    fig.savefig(f\"{PATH_TO_FIGS}/{NAME}/{batch_size}/maps/GradCam_{case}_case_axial_batchSize_{batch_size}.png\", dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## cases 14, 143 and 202\n",
    "for test_scan_number in [0, 23, 44]:\n",
    "\n",
    "    classes = {0:\"AD\", 1:\"MCI\", 2:\"CN\"}\n",
    "\n",
    "    scans, labels = test_dataset[test_scan_number] #scans 4D, labels\n",
    "    case = classes[labels.item()]\n",
    "    \n",
    "    print(f\"Scan is of class: {case}\")\n",
    "    \n",
    "    #preparing each scans\n",
    "    #class prediction\n",
    "    pred_ix = predict_label(scans.to(device))\n",
    "    #scan that is used to get the attributions\n",
    "    interpretation_scan = scans.unsqueeze(0)\n",
    "    \n",
    "    print(f'true label is: {case}, prediction class is {pred_ix}')\n",
    "    print('\\n')\n",
    "\n",
    "    saliency = Saliency(model)\n",
    "    attributions_saliency = saliency.attribute(interpretation_scan.to(device), target=pred_ix, abs=True)\n",
    "    \n",
    "\n",
    "    selected_scan_grad = np.abs(attributions_saliency.squeeze().cpu().detach().numpy())\n",
    "    selected_scan_grad = min_max_norm(selected_scan_grad)\n",
    "\n",
    "    #nifti image\n",
    "    scans = scans[0].numpy()\n",
    "    \n",
    "    #------------------SAGITTAL---------------------#\n",
    "    ### SHOWING EVERY SECOND SLICE, FROM 23 TO 140 ###\n",
    "    fig = plt.figure(figsize=(12, 14))\n",
    "    cb_ax = fig.add_axes([.91,.124,.04,.754])\n",
    "    for i, slice_x in enumerate(range(40, 120, 2)):\n",
    "        #Activation values = (selected_slice_grad_x>grad_constraint)\n",
    "        selected_slice_grad_x = np.rot90(selected_scan_grad[slice_x, :, :])\n",
    "        selected_scan_x = np.rot90(scans[slice_x, :, :])\n",
    "        \n",
    "        alpha_x = np.zeros(selected_slice_grad_x.shape)\n",
    "        alpha_x[selected_slice_grad_x>grad_constraint]=alpha_plt_value\n",
    "\n",
    "        ax = fig.add_subplot(8,5,i+1)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.imshow(selected_scan_x, cmap=\"gray\")\n",
    "        ax.imshow(selected_slice_grad_x, cmap=plt.cm.inferno, alpha = alpha_x)\n",
    "        ax.annotate(f\"slice {slice_x}\", (0,0), xytext=(50.0,-3.0), xycoords='data', fontsize=\"large\")\n",
    "\n",
    "    #fig.tight_layout()\n",
    "    fig.subplots_adjust(wspace=0, hspace=0)\n",
    "    fig.colorbar(cm.ScalarMappable(cmap=plt.cm.inferno), cax=cb_ax)\n",
    "    fig.savefig(f\"{PATH_TO_FIGS}/{NAME}/{batch_size}/maps/saliency_{case}_case_sagittal_batchSize_{batch_size}.png\", dpi=100)\n",
    "    \n",
    "    \n",
    "    #------------------CORONAL----------------------#\n",
    "    fig = plt.figure(figsize=(12, 14))\n",
    "    cb_ax = fig.add_axes([.91,.124,.04,.754])\n",
    "\n",
    "    for i, slice_y in enumerate(range(23, 141, 3)):\n",
    "        selected_slice_grad_y = np.rot90(selected_scan_grad[:, slice_y, :])\n",
    "        selected_scan_y = np.rot90(scans[:, slice_y, :])\n",
    "        alpha_y = np.zeros(selected_slice_grad_y.shape)\n",
    "        alpha_y[selected_slice_grad_y>grad_constraint]=alpha_plt_value\n",
    "\n",
    "\n",
    "        ax = fig.add_subplot(8,5,i+1)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.imshow(selected_scan_y, cmap=\"gray\")\n",
    "        ax.imshow(selected_slice_grad_y, cmap=plt.cm.inferno, alpha = alpha_y)\n",
    "        ax.annotate(f\"slice {slice_y}\", (0,0), xytext=(50.0,-3.0), xycoords='data', fontsize=\"large\")\n",
    "\n",
    "    #fig.tight_layout()\n",
    "    fig.subplots_adjust(wspace=0, hspace=0)\n",
    "    fig.colorbar(cm.ScalarMappable(cmap=plt.cm.inferno), cax=cb_ax)\n",
    "    fig.savefig(f\"{PATH_TO_FIGS}/{NAME}/{batch_size}/maps/saliency_{case}_case_coronal_batchSize_{batch_size}.png\", dpi=100)\n",
    "    \n",
    "    \n",
    "    #------------------AXIAL----------------------#\n",
    "    fig = plt.figure(figsize=(12,18.5))\n",
    "    cb_ax = fig.add_axes([.91,.124,.04,.754])\n",
    "\n",
    "    for i, slice_z in enumerate(range(0, 96, 2)):\n",
    "        selected_slice_grad_z = selected_scan_grad[:, :, slice_z]\n",
    "        selected_scan_z = scans[:, :, slice_z]\n",
    "\n",
    "        alpha_z = np.zeros(selected_slice_grad_z.shape)\n",
    "        alpha_z[selected_slice_grad_z>grad_constraint]=alpha_plt_value\n",
    "\n",
    "        ax = fig.add_subplot(8,6,i+1)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.imshow(selected_scan_z, cmap=\"gray\")\n",
    "        ax.imshow(selected_slice_grad_z, cmap=plt.cm.inferno, alpha = alpha_z)\n",
    "        ax.annotate(f\"slice {slice_z}\", (0,0), xytext=(50.0,-3.0), xycoords='data', fontsize=\"large\")\n",
    "\n",
    "    #fig.tight_layout()\n",
    "    fig.subplots_adjust(wspace=0, hspace=0)\n",
    "    fig.colorbar(cm.ScalarMappable(cmap=plt.cm.inferno), cax=cb_ax)\n",
    "    fig.savefig(f\"{PATH_TO_FIGS}/{NAME}/{batch_size}/maps/saliency_{case}_case_axial_batchSize_{batch_size}.png\", dpi=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# for plotting\n",
    "grad_constraint = 0\n",
    "alpha_plt_value = 0.4\n",
    "## cases 14, 143 and 202\n",
    "for test_scan_number in [0, 23, 44]:\n",
    "\n",
    "    classes = {0:\"AD\", 1:\"MCI\", 2:\"CN\"}\n",
    "\n",
    "    scans, labels = test_dataset[test_scan_number] #scans 4D, labels\n",
    "    case = classes[labels.item()]\n",
    "    \n",
    "    print(f\"Scan is of class: {case}\")\n",
    "    pred_ix = predict_label(scans.to(device))\n",
    "    scans = scans.unsqueeze(0)\n",
    "    \n",
    "    start_time = int(time.time())\n",
    "    occlusion = Occlusion(model)\n",
    "    attributions_occ = occlusion.attribute(scans.to(device),\n",
    "                                       strides = (1, 5, 5, 3),\n",
    "                                       target=pred_ix,\n",
    "                                       sliding_window_shapes=(1, 5, 5, 3),\n",
    "                                       baselines=0)\n",
    "    end_time = (time.time() - start_time)\n",
    "    print('\\n')\n",
    "    print('-------------------------------------------------------')\n",
    "    print(f'Time in (s) taken for completting scan of class:{case}')\n",
    "    print(end_time)\n",
    "    print('-------------------------------------------------------')\n",
    "    #removing first dimension which is 1 in order to obtain same\n",
    "    #dimension as transformed scan\n",
    "\n",
    "    selected_scan_grad = np.abs(attributions_occ.squeeze().cpu().detach().numpy())\n",
    "    selected_scan_grad = min_max_norm(selected_scan_grad)\n",
    "    #nifti image\n",
    "    scans = scans[0].numpy()\n",
    "    \n",
    "    #------------------SAGITTAL---------------------#\n",
    "    ### SHOWING EVERY SECOND SLICE, FROM 23 TO 140 ###\n",
    "    fig = plt.figure(figsize=(12, 14))\n",
    "    cb_ax = fig.add_axes([.91,.124,.04,.754])\n",
    "    for i, slice_x in enumerate(range(40, 120, 2)):\n",
    "        #Activation values = (selected_slice_grad_x>grad_constraint)\n",
    "        selected_slice_grad_x = np.rot90(selected_scan_grad[slice_x, :, :])\n",
    "        selected_scan_x = np.rot90(scans[slice_x, :, :])\n",
    "        \n",
    "        alpha_x = np.zeros(selected_slice_grad_x.shape)\n",
    "        alpha_x[selected_slice_grad_x>grad_constraint]=alpha_plt_value\n",
    "\n",
    "        ax = fig.add_subplot(8,5,i+1)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.imshow(selected_scan_x, cmap=default_cmap)\n",
    "        ax.imshow(selected_slice_grad_x, cmap='CMRmap', alpha = alpha_x)\n",
    "        ax.annotate(f\"slice {slice_x}\", (0,0), xytext=(50.0,-3.0), xycoords='data', fontsize=\"large\")\n",
    "\n",
    "    #fig.tight_layout()\n",
    "    fig.subplots_adjust(wspace=0, hspace=0)\n",
    "    fig.colorbar(cm.ScalarMappable(cmap='CMRmap'), cax=cb_ax)\n",
    "    fig.savefig(f\"{PATH_TO_FIGS}/{NAME}/{batch_size}/maps/Occlusion_{case}_case_sagittal_batchSize_{batch_size}.png\", dpi=100)\n",
    "    \n",
    "    \n",
    "    #------------------CORONAL----------------------#\n",
    "    fig = plt.figure(figsize=(12, 14))\n",
    "    cb_ax = fig.add_axes([.91,.124,.04,.754])\n",
    "\n",
    "    for i, slice_y in enumerate(range(23, 141, 3)): #23, 141, 3\n",
    "        selected_slice_grad_y = np.rot90(selected_scan_grad[:, slice_y, :])\n",
    "        selected_scan_y = np.rot90(scans[:, slice_y, :])\n",
    "        alpha_y = np.zeros(selected_slice_grad_y.shape)\n",
    "        alpha_y[selected_slice_grad_y>grad_constraint]=alpha_plt_value\n",
    "\n",
    "\n",
    "        ax = fig.add_subplot(8,5,i+1)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.imshow(selected_scan_y, cmap=default_cmap)\n",
    "        ax.imshow(selected_slice_grad_y, cmap='CMRmap', alpha = alpha_y)\n",
    "        ax.annotate(f\"slice {slice_y}\", (0,0), xytext=(50.0,-3.0), xycoords='data', fontsize=\"large\")\n",
    "\n",
    "    #fig.tight_layout()\n",
    "    fig.subplots_adjust(wspace=0, hspace=0)\n",
    "    fig.colorbar(cm.ScalarMappable(cmap='CMRmap'), cax=cb_ax)\n",
    "    fig.savefig(f\"{PATH_TO_FIGS}/{NAME}/{batch_size}/maps/Occlusion_{case}_case_coronal_batchSize_{batch_size}.png\", dpi=100)\n",
    "    \n",
    "    \n",
    "    #------------------AXIAL----------------------#\n",
    "    fig = plt.figure(figsize=(12,18.5))\n",
    "    cb_ax = fig.add_axes([.91,.124,.04,.754])\n",
    "\n",
    "    for i, slice_z in enumerate(range(0, 96, 2)):\n",
    "        selected_slice_grad_z = selected_scan_grad[:, :, slice_z]\n",
    "        selected_scan_z = scans[:, :, slice_z]\n",
    "\n",
    "        alpha_z = np.zeros(selected_slice_grad_z.shape)\n",
    "        alpha_z[selected_slice_grad_z>grad_constraint]=alpha_plt_value\n",
    "\n",
    "        ax = fig.add_subplot(8,6,i+1)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.imshow(selected_scan_z, cmap=default_cmap)\n",
    "        ax.imshow(selected_slice_grad_z, cmap='CMRmap', alpha = alpha_z)\n",
    "        ax.annotate(f\"slice {slice_z}\", (0,0), xytext=(50.0,-3.0), xycoords='data', fontsize=\"large\")\n",
    "\n",
    "    #fig.tight_layout()\n",
    "    fig.subplots_adjust(wspace=0, hspace=0)\n",
    "    fig.colorbar(cm.ScalarMappable(cmap='CMRmap'), cax=cb_ax)\n",
    "    fig.savefig(f\"{PATH_TO_FIGS}/{NAME}/{batch_size}/maps/Occlusion_{case}_case_axial_batchSize_{batch_size}.png\", dpi=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
